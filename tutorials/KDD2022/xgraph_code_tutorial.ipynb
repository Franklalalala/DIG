{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tutorial for GNN Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this hand-on code tutorial, we will show how to apply our DIG xgraph APIs to explain a well-trained model. Specifically, we will demonstrate two methods **GNNExplainer** and **SubgraphX** on the node classification dataset BA-shapes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GNN explainability\n",
    "Graph Neural Networks are usually treated as black-boxes and lacking explainability. Without reasoning the prediction procedures of GNNs, we do not understand GNN models and do not know whether the models work in our expected way, thus preventing their use in critical applications pertaining to fairness, privacy, and safety."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the dataset BA-shapes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as osp\n",
    "sys.path.insert(0, os.sep.join(os.path.abspath('').split(os.sep)[:-2]))\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "from dig.xgraph.dataset import SynGraphDataset\n",
    "from dig.xgraph.models import *\n",
    "from dig.xgraph.utils.compatibility import compatible_state_dict\n",
    "from dig.xgraph.utils.init import fix_random_seed\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "fix_random_seed(123)\n",
    "dataset = SynGraphDataset('./datasets', 'BA_shapes')\n",
    "dataset.data.x = dataset.data.x.to(torch.float32)\n",
    "dataset.data.x = dataset.data.x[:, :1]\n",
    "dim_node = dataset.num_node_features\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "data = dataset[0]\n",
    "target_node_indices = torch.where(dataset[0].test_mask * dataset[0].y != 0)[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the well-trained GCN model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_checkpoints(root='./'):\n",
    "    if osp.exists(osp.join(root, 'checkpoints')):\n",
    "        return\n",
    "    url = ('https://github.com/divelab/DIG_storage/raw/main/xgraph/checkpoints.zip')\n",
    "    path = download_url(url, root)\n",
    "    extract_zip(path, root)\n",
    "    os.unlink(path)\n",
    "\n",
    "\n",
    "model = GCN_2l(model_level='node', dim_node=dim_node, dim_hidden=300, num_classes=num_classes)\n",
    "model.to(device)\n",
    "check_checkpoints()\n",
    "ckpt_path = osp.join('checkpoints', 'ba_shapes', 'GCN_2l', '0', 'GCN_2l_best.ckpt')\n",
    "state_dict = compatible_state_dict(torch.load(ckpt_path, map_location='cpu')['state_dict'])\n",
    "model.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GNNExplainer\n",
    "\n",
    "GNNExplainer learns soft masks for edges and node features to identify important input information. The masks are randomly initialized and updated to maximize the mutual information between original predictions and perturbed graphs.\n",
    "Here we setup **GNNExplainer** and take it to explain the predictions for 20 target nodes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from dig.xgraph.method import GNNExplainer\n",
    "from dig.xgraph.evaluation import XCollector\n",
    "\n",
    "gnnexplainer = GNNExplainer(model, epochs=100, lr=0.01, explain_graph=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SubgraphX\n",
    "SubgraphX explores subgraph-level explanations for graph neural networks. It employs the Monte Carlo Tree Search algorithm to efficiently explore different subgraphs via node pruning and select the most important subgraph as the explanation. The importance of subgraphs is measured by Shapley values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from dig.xgraph.method import SubgraphX\n",
    "\n",
    "subgraphx_explainer = SubgraphX(model,\n",
    "                                num_classes=num_classes,\n",
    "                                device=device,\n",
    "                                explain_graph=False,\n",
    "                                reward_method='nc_mc_l_shapley')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metric\n",
    "Here we apply two metric Fidelity and Sparsity to compare these two explainability methods.\n",
    "Fidelity is the probability difference between the original prediction and new prediction when masking the important explanation results. In addition, Sparsity is the ratio of the number of edges not in the final explanation of edges.\n",
    "\n",
    " Next, we take GNNExplainer and SubgraphX to explain the same model predictions. Here we control similar sparsity scores and compare the fidelity score."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "sparsity = 0.15\n",
    "gnnexplainer_collector = XCollector()\n",
    "\n",
    "max_nodes = 5\n",
    "subgraphx_collector = XCollector()\n",
    "\n",
    "for data_idx, node_idx in enumerate(target_node_indices[:20]):\n",
    "    data.to(device)\n",
    "\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    prediction = logits[node_idx].argmax(-1).item()\n",
    "\n",
    "    gnnexplainer_edge_masks, \\\n",
    "    gnnexplainer_hard_edge_masks, \\\n",
    "    gnnexplainer_related_preds = \\\n",
    "        gnnexplainer(data.x, data.edge_index,\n",
    "                     sparsity=sparsity,\n",
    "                     num_classes=num_classes,\n",
    "                     node_idx=node_idx)\n",
    "\n",
    "    _, subgraphx_explanation_results, subgraphx_related_preds = \\\n",
    "        subgraphx_explainer(data.x, data.edge_index, node_idx=node_idx, max_nodes=max_nodes)\n",
    "    subgraphx_explanation_results = subgraphx_explanation_results[prediction]\n",
    "\n",
    "    gnnexplainer_collector.collect_data(\n",
    "        gnnexplainer_hard_edge_masks, gnnexplainer_related_preds, prediction)\n",
    "    subgraphx_collector.collect_data(\n",
    "        subgraphx_explanation_results[0]['coalition'], subgraphx_related_preds, label=prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNExplainer Fidelity: 0.7883\n",
      " GNNExplainer Sparsity: 0.1601\n",
      "SubgraphX Fidelity: 0.7900\n",
      " SubgraphX Sparsity: 0.1587\n"
     ]
    }
   ],
   "source": [
    "print(f'GNNExplainer Fidelity: {gnnexplainer_collector.fidelity:.4f}\\n',\n",
    "      f'GNNExplainer Sparsity: {gnnexplainer_collector.sparsity:.4f}')\n",
    "print(f'SubgraphX Fidelity: {subgraphx_collector.fidelity:.4f}\\n',\n",
    "      f'SubgraphX Sparsity: {subgraphx_collector.sparsity:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}